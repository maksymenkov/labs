## Комп'ютерні системи імітаційного моделювання
## СПм-22-5, **Максименков Олексій**
### Лабораторна робота №**3**. Використання засобів обчислювального интелекту для оптимізації імітаційних моделей

<br>

### 3 Варіант, модель у середовищі NetLogo:
[Virus](http://https://www.netlogoweb.org/launch#https://www.netlogoweb.org/assets/modelslib/Sample%20Models/Biology/Virus.nlogo)

<br>

#### Вербальний опис моделі:



### Налаштування середовища BehaviorSearch:

**Обрана модель**:
<pre>
Virus.nlogo
</pre>
**Параметри моделі** (вкладка Model):  

<pre>
["number-people" 150]
["infectiousness" [0 1 99]]
["duration" [0 1 99]]
["chance-recover" [0 1 99]]
</pre>

Для фітнес-функції було обрано **значення відсотка хворих людей у популяції**, для її розрахунку взято глобальну змінну **%infected** з коду моделі:
<pre>
  globals
  [ %infected            ;; what % of the population is infectious
    %immune              ;; what % of the population is immune
    lifespan             ;; the lifespan of a turtle
    chance-reproduce     ;; the probability of a turtle generating an offspring each tick
    carrying-capacity    ;; the number of turtles that can be in the world at one time
    immunity-duration ]  ;; how many weeks immunity lasts
</pre>
та вказано у параметрі "**Measure**":
<pre>
%infected 
</pre>

Відсоток хворих людей у популяції має розраховуватись в середньому за весь період симуляції тривалістю, адже потрібно знайти значення для ідеального вірусу, який весь час є у максимальній кількості людей.
Параметр "**Mesure if**" встановлено зі значенням true. Параметр зупинки за умовою ("**Stop if**") не використовувався. При симуляції зі значенням **Stop if** викривлялися результати, тому він не використовувався.
Загальний вигляд вкладки налаштувань параметрів моделі:  
![Вкладка налаштувань параметрів моделі](model.png)

**Налаштування цільової функції** (вкладка Search Objective):  
Метою підбору параметрів імітаційної моделі для визначення значення "**%infected**" (відсоток хворих людей у популяції) є максимізація цього показника через параметр "**Goal**" зі значенням "**Maximize Fitness**". Це означає, що необхідно налаштувати параметри моделі так, щоб досягти максимально можливого значення "%інфікованих" в популяції, тобто знайти найпристосованіший і найживучіший вірус.

Для досягнення цієї мети, використовується параметр "**Collected measure**", який вказує спосіб обліку цього показника. У цьому випадку, встановлено значення "**MEAN_ACROSS_STEPS**". Це означає, що цікавить не просто значення "**%infected**" в певний момент симуляції, а середнє значення цього показника за весь час проведення симуляції.

Для зниження впливу випадкових факторів на результати, кожна симуляція проводиться десять разів, і після цього результат розраховується як середнє арифметичне цих десяти запусків. Це допомагає зменшити випадкові відхилення і забезпечити більш надійний результат.
Загальний вигляд вкладки налаштувань цільової функції: 

![Вкладка налаштувань цільової функції](searchobjective.png)

**Налаштування алгоритму пошуку** (вкладка Search Algorithm):  

Загальний вид вкладки налаштувань алгоритму пошуку:  
![Вкладка налаштувань пошуку](search.png)

<br>

### Результати використання BehaviorSearch:
Діалогове вікно запуску пошуку :  
![Вікно запуску пошуку](searchstart.png)
Результат пошуку параметрів імітаційної моделі, використовуючи **генетичний алгоритм**:  
![Результати пошуку за допомогою ГА](result1.png)
Результат пошуку параметрів імітаційної моделі, використовуючи **випадковий пошук**:  
![Результати випадкового пошуку](result2.png)

### Контрольні запитання
- **Навіщо потрібна оптимізаційна модель?**

Оптимізаційна модель має вирішальне значення в багатьох сферах і додатках, оскільки вона забезпечує систематичний і кількісний підхід до прийняття найкращих можливих рішень з урахуванням певних обмежень і цілей.
Прийняття рішень в умовах обмежень: Багато реальних проблем пов'язані з прийняттям рішень за наявності обмежень (наприклад, обмеженість ресурсів, часу, бюджету). Оптимізаційні моделі допомагають визначити найбільш ефективний і результативний спосіб розподілу цих обмежених ресурсів для досягнення найкращого можливого результату.
Максимізація або мінімізація цілей: Оптимізаційні моделі призначені для пошуку найкращого рішення, яке максимізує або мінімізує певну мету, таку як прибуток, витрати, ефективність або продуктивність. Це важливо в бізнесі, інженерії, економіці та інших галузях.
Робота зі складними завданнями: Багато проблем, особливо в інженерії та бізнесі, занадто складні для інтуїтивних рішень. Оптимізаційні моделі можуть обробляти складні взаємозв'язки між різними змінними, що дозволяє приймати більш обґрунтовані та надійні рішення.
Кількісний аналіз: Оптимізація забезпечує основу для кількісного аналізу. Вона перетворює якісні проблеми в кількісні моделі, дозволяючи використовувати математичні інструменти і методи для вирішення проблем.
Прогностичні можливості: Оптимізаційні моделі можна використовувати для прогнозування результатів різних рішень або сценаріїв, що дозволяє організаціям та окремим особам оцінювати потенційні стратегії до їх реалізації.
Оптимізація ресурсів: У таких галузях, як виробництво, логістика та управління ланцюгами поставок, оптимізаційні моделі мають вирішальне значення для мінімізації витрат і максимізації ефективності використання ресурсів.
Підвищення якості та продуктивності: Оптимізаційні моделі сприяють вдосконаленню процесів, визначаючи найефективніші способи підвищення продуктивності та якості, що часто призводить до інновацій у процесах і методах.
Управління ризиками: У сфері фінансів та інвестицій оптимізаційні моделі допомагають формувати портфелі, балансуючи компроміс між ризиком і прибутковістю, що сприяє ефективному управлінню ризиками.
Сталий розвиток та управління навколишнім середовищем: Оптимізаційні моделі все частіше використовуються для вирішення екологічних проблем, таких як мінімізація відходів або вуглецевого сліду, а також управління використанням відновлюваних ресурсів.
Технологічна інтеграція: З розвитком технологій, особливо в таких сферах, як машинне навчання і штучний інтелект, оптимізаційні моделі стали більш досконалими і можуть бути інтегровані з цими технологіями для розширення можливостей прийняття рішень.
- **Які етапи використання середовища BehaviorSearch?**

Етапи використання середовища BehaviorSearch зазвичай включають наступні кроки:
Визначення моделі в NetLogo -> Визначення простору пошуку (визначення діапазону і деталізацію значень, які може приймати кожен параметр.) -> Налаштування цільової функції -> Вибір алгоритму пошуку -> Запуск пошуку
- **Що таке цільова функція (функція пристосованості)?**

Цільова функція, також відома як функція пристосованості в контексті оптимізації та еволюційних алгоритмів, - це математичний вираз, який використовується для оцінки того, наскільки добре запропоноване рішення або набір рішень задовольняє встановленим критеріям або цілям даної проблеми. В задачах оптимізації вона кількісно оцінює якість рішення, а метою часто є пошук рішення, яке максимізує або мінімізує цю функцію.
- **Як ви розумієте поняття "простору пошуку"?**

відноситься до всієї множини можливих рішень або конфігурацій, які можуть бути розглянуті при вирішенні задачі. Він представляє всі можливі точки або комбінації, які алгоритм може дослідити, щоб знайти найкраще рішення або задовольнити певні критерії.
З практичної точки зору, простір пошуку можна візуалізувати як багатовимірний ландшафт, де кожен вимір відповідає змінній або параметру задачі. Розмір і характер цього простору визначаються кількістю змінних і діапазоном значень, які кожна з них може приймати. Наприклад, у простій оптимізаційній задачі з двома змінними, кожна з яких може набувати будь-якого значення від 0 до 10, простір пошуку буде мати вигляд сітки 10х10.
Складність і розмір області пошуку безпосередньо впливають на складність задачі. Більші та складніші простори часто вимагають складніших алгоритмів для ефективного пошуку оптимальних рішень. Такі методи, як генетичні алгоритми, імітація відпалу або градієнтний спуск, орієнтуються в цьому просторі по-різному, але всі вони спрямовані на пошук точок (рішень), які найкраще відповідають визначеним цілям або обмеженням задачі.
- **Які алгоритми пошуку доступні у середовищі BehaviorSearch?**

Genetic Algorithms
MutationHillClimber
SimulatedAnnealing
Random Search
- **У чому полягає метод випадкового пошуку?**

Метод випадкового пошуку - це простий метод оптимізації, коли рішення генеруються випадковим чином у визначеному просторі пошуку. На відміну від структурованих методів оптимізації, які слідують певним правилам або градієнтам, випадковий пошук покладається на генерацію випадкових рішень без будь-якого керованого напрямку до оптимуму.

У цьому методі випадковим чином вибирається велика кількість кандидатів на рішення, і їх ефективність оцінюється за допомогою цільової функції або функції пристосованості. Найкраще рішення, знайдене під час цієї випадкової вибірки, стає запропонованим рішенням проблеми.

Ключовою перевагою випадкового пошуку є його простота і той факт, що він не залежить від початкових стартових умов або конкретних припущень про природу простору пошуку. Це робить його особливо корисним у випадках, коли простір пошуку є складним, нелінійним або погано вивченим, оскільки він може досліджувати області простору, які можуть бути проігноровані більш детермінованими методами.

Однак ефективність випадкового пошуку знижується зі збільшенням розміру та складності пошукової області. У великих або складних просторах пошуку ймовірність випадкового знаходження близького до оптимального рішення стає дуже низькою, що робить випадковий пошук менш ефективним у порівнянні з більш складними методами, такими як генетичні алгоритми або методи оптимізації на основі градієнта.
- **У чому різниця між середнім арифметичним значенням та медіаною?**

в той час як середнє значення забезпечує математичне середнє, медіана пропонує середню точку, яка ділить набір даних на дві рівні половини, і часто є більш надійною за наявності викидів або викривлених даних.
- **Які можуть використовуватися критерії зупинки пошуку?**

Досягнення заданого рівня придатності. Досягнення максимальної кількості ітерацій або ліміту часу. Збіжність розв'язків, що свідчить про неможливість подальшого покращення.
- **Які основні етапи роботи генетичного алгоритму?**

Ініціалізація: Цей перший крок передбачає створення початкової популяції індивідів (розв'язків). 
Оцінювання: На цьому етапі оцінюється придатність кожної особини в популяції. Функція придатності, унікальна для кожної проблеми, оцінює, наскільки добре індивід вирішує проблему або відповідає бажаним критеріям.
Відбір: На основі значень їхньої фізичної підготовленості відбираються особини для участі в наступному поколінні. Методи відбору, такі як відбір на колесі рулетки, турнірний відбір або відбір за рангом, використовуються для імовірнісного відбору особин, при цьому перевага надається тим, хто має вищий рівень.
Схрещування: На цьому етапі відібрані особини об'єднуються в пари і комбінуються, щоб створити потомство для наступного покоління. Кросинговер - це генетичний оператор, який використовується для обміну інформацією (генами) між батьківськими рішеннями, створюючи нове потомство, яке успадковує характеристики від обох батьків. Точка(и) кросинговеру і спосіб обміну генами залежать від конкретної техніки кросинговеру, що використовується.
Мутація: Після кросинговеру нащадки можуть зазнати мутації, коли в деяких генах відбуваються випадкові зміни. Цей процес вносить генетичне різноманіття в популяцію і допомагає запобігти передчасній конвергенції до неоптимальних рішень.
Заміна: Новостворене потомство замінює частину або всю поточну популяцію, утворюючи нове покоління. Стратегія заміни може бути різною: деякі алгоритми зберігають суміш старих і нових особин, тоді як інші замінюють всю популяцію новими нащадками.
Завершення: Цей заключний етап визначає, коли алгоритм має зупинитися. Найпоширеніші умови припинення включають досягнення максимальної кількості поколінь, досягнення задовільного рівня пристосованості або стагнацію в поліпшенні популяції.


частота мутацій - ймовірність виникнення мутації у кожної дитини
розмір популяції - кількість особин у кожному поколінні
розмір турніру - для турнірного відбору це кількість особин, які змагаються за вибір особини, що отримає право на розмноження.
модель популяції - "генерація", "стаціонарна заміна-випадкова" або "стаціонарна заміна-найгірша" - генерація означає, що вся популяція замінюється одразу, тоді як стаціонарна означає, що на кожній ітерації відтворення замінюється лише одна особина - або випадково обрана, або найгірша з поточних особин.
частота кросинговеру - ймовірність використання двох батьків для створення дитини (в іншому випадку дитина створюється нестатевим шляхом)

- **Які генетичні оператори вам відомі?**

Селекція: Цей оператор відповідає за відбір особин з поточної популяції для створення потомства для наступного покоління. Ідея полягає в тому, щоб відбирати найкращих особин, щоб їхні риси передавалися далі. Поширені методи відбору включають відбір за допомогою колеса рулетки, турнірний відбір та відбір за рангом.
Кросовер (рекомбінація): Кросовер поєднує генетичну інформацію двох батьківських особин для отримання одного або декількох нащадків. Він імітує біологічне розмноження, де нащадки успадковують ознаки від обох батьків. Існують різні техніки кросинговеру, такі як одноточковий кросинговер, багатоточковий кросинговер і рівномірний кросинговер.
Мутація: Мутація вносить випадкові зміни в генетичний склад особини. Це може бути зміна одного гена (у двійковому рядку, перекидання біта з 0 на 1 або навпаки) або більш складні зміни. Мутація вносить мінливість у популяцію, що може допомогти запобігти передчасній збіжності до неоптимальних рішень і дослідити нові області простору пошуку.
- **Що таке кросовер? Як відбувається відбір особин для нього?**

це генетичний оператор, який використовується для об'єднання генетичної інформації двох батьківських особин для отримання нового потомства. Основна ідея кросоверу полягає у створенні нащадків, які потенційно успадкують найкращі риси від кожного з батьків, таким чином досліджуючи нові точки в просторі рішень.

Як працює кросовер:
Вибір батьків: Перш ніж відбудеться схрещування, батьківські особини повинні бути відібрані з поточної популяції. Цей відбір зазвичай ґрунтується на їхній пристосованості, причому особини з вищими показниками пристосованості мають більшу ймовірність бути обраними. Однак точний метод відбору може відрізнятися.
Визначення точок схрещування: Після відбору батьків визначають одну або декілька точок кросинговеру. Ці точки визначають, як генетична інформація батьків буде об'єднана.
Поєднання генетичного матеріалу: Генетичний матеріал (часто представлений у вигляді рядків символів, наприклад, двійкових чисел або дійсних чисел) батьків потім поєднується в точках схрещування для отримання нового потомства. Наприклад, при одноточковому кросинговері ви можете взяти першу частину генетичного рядка одного з батьків і об'єднати її з другою частиною рядка іншого батька.

Методи відбору для кросинговеру:

Відбір за допомогою колеса рулетки: Особи відбираються імовірнісно, з ймовірністю, пропорційною їхній фізичній підготовці. Вища фізична підготовка збільшує шанс бути обраним.
Турнірний відбір: Випадковим чином вибирається підмножина особин, і особа з найвищою пристосованістю в цій підмножині обирається як батько.
Ранговий відбір: Особини ранжуються на основі фітнесу, і відбір відбувається на основі цього ранжування, що допомагає підтримувати різноманітність і запобігає передчасній конвергенції.
Стохастична універсальна вибірка: Схожий на колесо рулетки, але більш ефективний у підтримці різноманітності. Кілька батьків відбираються за один оберт.
Елітарність: Іноді найкращі особини безпосередньо передаються наступному поколінню, а також допускаються до участі в кросинговері, щоб гарантувати, що якісні рішення не будуть втрачені.

- **Навіщо потрібен оператор мутації?**

Мутація вводить випадкові варіації, щоб запобігти передчасній збіжності алгоритму і дослідити нові області простору пошуку.
- **Які є способи кодування варіантів рішень (особин) у генетичному алгоритмі?**

StandardBinaryChromosome У цьому кодуванні кожен параметр перетворюється на рядок двійкових цифр, і ці послідовності об'єднуються в один великий бітовий масив. Мутація та кросинговер відбуваються побітно.
GrayBinaryChromosome Подібна до StandardBinaryChromosome, за винятком того, що числові значення кодуються у двійкові рядки за допомогою коду Грея, замість стандартного "старшого порядку" бітів. Коди Грея, як правило, дають кращу продуктивність для пошукових представлень, оскільки числові значення, які знаходяться близько одне до одного, з більшою ймовірністю мають менше мутацій одне від одного.
MixedTypeChromosome Це кодування найбільше відповідає тому, як зазвичай думають про параметри ABM. Кожен параметр зберігається окремо з власним типом даних (дискретний числовий, неперервний числовий, категоріальний, булевий тощо). Мутація застосовується до кожного параметра окремо (наприклад, для неперервних параметрів використовується гаусова мутація, а для булевих параметрів - перевертання).
RealHypercubeChromosome У цьому кодуванні кожен параметр (числовий чи ні) представлено неперервною змінною з дійсним значенням. Це кодування існує головним чином для полегшення (майбутнього) використання алгоритмів, які передбачають неперервний числовий простір (наприклад, оптимізація рою частинок), і дозволяє застосовувати їх навіть тоді, коли деякі з параметрів моделі не є числовими.

- **Недоліки та переваги використання генетичних алгоритмів.**

Переваги:
Добре підходить для складних завдань: ГА ефективні для складних проблем, де традиційні методи не справляються, особливо коли простір пошуку великий або погано вивчений.
Паралелізм: Вони можуть досліджувати кілька рішень одночасно, що може бути корисним у мультимодальних ландшафтах.
Гнучкість: ГА адаптуються до різних типів проблем і можуть працювати з різними типами даних.

Недоліки:
Обчислювальна інтенсивність: ГА можуть бути ресурсоємними, вимагаючи значних обчислювальних потужностей для вирішення складних завдань.
Відсутність гарантії оптимального рішення: Вони не завжди знаходять глобальний оптимум і можуть сходитися до субоптимальних розв'язків.
Налаштування параметрів: Продуктивність ГА сильно залежить від вибору параметрів, таких як розмір популяції, швидкість мутацій і швидкість кросинговеру, які може бути складно встановити оптимально.
- **У чому полягає алгоритм імітації відпалу?**

Алгоритм імітаційного відпалу - це метод оптимізації, натхненний процесом відпалу в металургії. Він використовується для пошуку наближеного глобального оптимуму у великому просторі пошуку. Алгоритм допускає випадкові рухи в гору, зменшуючи ймовірність застрягання в локальних оптимумах. Це досягається шляхом поступового зменшення параметра "температури", контролюючи ймовірність прийняття гірших рішень у процесі роботи алгоритму. Спочатку високі температури дозволяють проводити більш випадкові дослідження, але зі зниженням температури алгоритм все більше віддає перевагу ходам, які покращують рішення. Такий баланс між пошуком та експлуатацією допомагає знаходити близькі до оптимальних рішення в складних проблемних просторах.

- **У чому полягає метод пошуку сходженням до вершини?**

Алгоритм пошуку "сходження на гору" - це евристичний метод пошуку локального оптимуму в просторі пошуку. Він починається з випадкового рішення та ітеративно вносить невеликі зміни, зберігаючи покращення, щоб наблизитися до оптимуму. Цей метод схожий на сходження в гору, завжди шукаючи вищу точку. Однак він може застрягти на локальних оптимумах і не знайти глобального оптимуму, особливо в складних ландшафтах з багатьма вершинами. Він простий і ефективний для вирішення певних проблем, але обмежений локальною перспективою.

Евристичний метод - це підхід до вирішення проблем, який використовує практичну, несистематичну стратегію для пошуку задовільних рішень. Ці методи особливо корисні, коли вичерпний пошук є недоцільним. Евристики спрощують складні проблеми, використовуючи емпіричні правила, обґрунтовані здогадки, інтуїцію або здоровий глузд, пропонуючи швидше прийняття рішень, ніж більш формальні методи. Однак вони не гарантують оптимального або досконалого рішення, але можуть забезпечити достатньо хороше рішення в розумні терміни, особливо в ситуаціях, коли весь простір пошуку занадто великий або недостатньо вивчений.

Локальний оптимум в контексті оптимізаційних задач - це рішення, яке краще або дорівнює всім найближчим рішенням, але в ширшому просторі пошуку можуть існувати інші рішення, які є кращими. Це схоже на досягнення вершини невеликого пагорба в ландшафті пагорбів і долин. У складних задачах з декількома вершинами (локальними оптимумами) і долинами (локальними мінімумами) пошук глобального оптимуму (найвищої вершини) може бути складним, оскільки алгоритми можуть "застрягти" на локальному оптимумі, вважаючи його найкращим загальним рішенням.